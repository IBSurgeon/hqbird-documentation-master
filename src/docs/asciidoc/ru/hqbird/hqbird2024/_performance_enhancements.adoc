[[hqbird-performance]]
= Улучшения производительности

[[hqbird-performance-extconn-pool]]
== Пул внешних подключений

HQbird поддерживает пул внешних подключений для Firebird 2.5 и Firebird 3. Стандартная сборка Firebird 4.0 и выше поддерживает создание внешних пулов соединений "`из коробки`". 

Пул внешних подключений позволяет выполнять инструкции `EXECUTE STATEMENT ON EXTERNAL` с меньшими затратами на повторное соединение с внешней базой данных.

[NOTE]
====
Обратите внимание: этот пул выделяется для каждого экземпляра Firebird.
====

Эта функция настраивается в файле `firebird.conf`:

[source]
----
# ============================
# Settings of External Connections Pool
# ============================

# Set the maximum number of inactive (idle) external connections to retain at
# the pool. Valid values are between 0 and 1000.
# If set to zero, pool is disabled,
# i.e. external connection is destroyed immediately after the use.
#
# Type: integer
#
#ExtConnPoolSize = 0

# Set the time before destroying inactive external connection, seconds.
# Valid values are between 1 and 86400.
#
# Type: integer
#
#ExtConnPoolLifeTime = 7200
----

С точки зрения приложения не требуется никаких дополнительных действий для использования или неиспользования -- пул включается или отключается в конфигурации сервера и абсолютно незаметно для приложений.

Для управления пулом существуют следующие команды:

* изменение размера пула
+
[source]
----
ALTER EXTERNAL CONNECTIONS POOL SET SIZE N
----
+
Пример: эта команда устанавливает размер пула на 190 подключений.
+
[source,sql]
----
ALTER EXTERNAL CONNECTIONS POOL SET SIZE 190
----
* изменение времени жизни неактивного соединение в пуле
+
[source]
----
ALTER EXTERNAL CONNECTIONS POOL
SET LIFETIME N {SECOND | MINUTE | HOUR}
----
+
Пример: эта команда ограничивает время жизни соединения в пуле до 1 часа.
+
[source,sql]
----
ALTER EXTERNAL CONNECTIONS POOL SET LIFETIME 1 HOUR
----
* очистить все соединения в пуле
+
[source,sql]
----
ALTER EXTERNAL CONNECTIONS POOL CLEAR ALL
----
* очистить самое старое соединение в пуле
+
[source,sql]
----
ALTER EXTERNAL CONNECTIONS POOL CLEAR OLDEST
----

Для получения информации о состоянии пула были введены новые контекстные переменные. Следующий пример демонстрирует их использование

[source,sql]
----
SELECT
  CAST(RDB$GET_CONTEXT('SYSTEM', 'EXT_CONN_POOL_SIZE') AS INT) AS POOL_SIZE,
  CAST(RDB$GET_CONTEXT('SYSTEM', 'EXT_CONN_POOL_IDLE_COUNT') AS INT) AS POOL_IDLE,
  CAST(RDB$GET_CONTEXT('SYSTEM', 'EXT_CONN_POOL_ACTIVE_COUNT') AS INT) AS POOL_ACTIVE,
  CAST(RDB$GET_CONTEXT('SYSTEM', 'EXT_CONN_POOL_LIFETIME') AS INT) AS POOL_LIFETIME
FROM RDB$DATABASE;
----

<<<

== Кеш подготовленных запросов

В HQbird есть возможность улучшить производительность движка Firebird (версии 4.0 и 5.0) в случае большого количества частых и быстрых SQL-запросов: кэширование подготовленных операторов SQL на стороне сервера. Начиная с Firebird 5.0 эта функция доступна в стандартной сборке "`из коробки`". 

=== Кеш подготовленных запросов в Firebird 3.0 и 4.0

Эту функцию можно включить в `firebird.conf` с помощью параметра `DSQLCacheSize`:

[source]
----
# Size of DSQL statements cache.
# Maximum number of statements to cache.
# Use with care as it is per-attachment and could lead to big memory usage.
# Value of zero disables caching.
# Per-database configurable.
# Type: integer
#DSQLCacheSize = 0
----

Это число указывает, сколько последних запросов для каждого подключения к базе данных необходимо кэшировать.

Чтобы применить новое значение, потребуется перезапуск Firebird.

По умолчанию `DSQLCacheSize` равен 0, что означает выключен. Мы рекомендуем осторожно включать его: начните со значений, таких как 4, 8, 16, чтобы найти лучший эффект производительности.

[NOTE]
====
Обратите внимание: включение кэширования подготовленных операторов увеличивает использование памяти.
====

=== Кеш подготовленных запросов в Firebird 5.0

В Firebird 5.0 кеш подготовленных запросов был переработан и включён в "`ванильную`" сборку. 

Кеш подготовленных запросов управляется параметром `MaxStatementCacheSize` в `firebird.conf`.

----
# ----------------------------
# Maximum statement cache size
#
# The maximum amount of RAM used to cache unused DSQL compiled statements.
# If set to 0 (zero), statement cache is disabled.
#
# Per-database configurable.
#
# Type: integer
#
#MaxStatementCacheSize = 2M
----

По умолчанию кеш подготовленных запросов включен. Для его отключения необходимо установить параметр `MaxStatementCacheSize` в 0.

<<<

== TempSpaceLogThreshold: мониторинг запросов с большими сортировками и BLOB

HQbird имеет новый параметр в `firebird.conf` in Firebird 2.5, Firebird 3.0, Firebird 4.0 и Firebird 5.0:

[source]
----
TempSpaceLogThreshold=1000000000 #bytes
----

Когда Firebird видит этот параметр, он записывает тексты запросов в `firebird.log` для запросов, которые производят большие сортировки (запросы с `GROUP BY`, `ORDER BY` и т. д.).


Когда такой запрос создаст файл сортировки, размер которого превышает указанный порог, в `firebird.log` появится следующее сообщение:

----
SRV-DB1	Wed Nov 28 21:55:36 2018
	Temporary space of type "sort" has exceeded threshold of 1000000000 bytes.
	Total size: 10716980736, cached: 1455423488 bytes, on disk: 9263120384 bytes.
	Query: select count(*) from (select lpad('',1000,uuid_to_char(gen_uuid())) s
	       from rdb$types a,rdb$types b, rdb$types c  order by 1)
----

*Total size*:: общий размер файла сортировки

*Cached*:: часть сортировки, уместившаяся во временное пространство (задается параметром `TempCacheLimit`)

*On disk*:: часть сортировки, которая была сохранена во временный файл, который может быть кэширован в памяти ОС или сохранен на диске (в папке, указанной параметром `TempDirectories`, или в временной папке по умолчанию)

Для очень больших BLOB в файле `firebird.log` появится следующее сообщение

----
SRV-DB1	Tue Nov 27 17:35:39 2018
	Temporary space of type "blob" has exceeded threshold of 500000000 bytes.
	Total size: 500377437, cached: 0 bytes, on disk: 501219328 bytes.
----

Используйте `TempSpaceLogThreshold` для поиска неоптимизированных запросов с большой сортировкой и большими BLOB-объектами. Начиная с Firebird 3.0 в нём также будет сообщаться о больших хеш-таблицах (возникают при HASH JOIN).

Если вы столкнулись с такими запросами, оптимизируйте их либо путем изменения самого SQL-запроса, либо попробуйте включить параметр `SortDataStorageThreshold`.

<<<

== SortDataStorageThreshold: REFETCH вместо SORT для широких наборов данных

HQbird поддерживает новый метод оптимизации REFETCH. Стандартная сборка Firebird версии 4.0 и выше поддерживает этот алгоритм оптимизации "`из коробки`".

В HQbird появился новый параметр `SortDataStorageThreshold` в `firebird.conf` (Firebird 3.0+):

[source]
----
SortDataStorageThreshold=16384 # bytes
----

[NOTE]
====
Начиная с версии 4.0 этот параметр был переименован в `InlineSortThreshold`.

[source]
----
InlineSortThreshold=16384 # bytes
----
====

Если размер записи, возвращаемой SQL-запросом, будет больше указанного порога, Firebird будет использовать другой подход для сортировки наборов записей: REFETCH вместо SORT.

Например, у нас есть следующий запрос

[source]
----
select tdetl.name_detl
    ,tmain.name_main
    ,tdetl.long_description
from tdetl
join tmain on tdetl.pid=tmain.id
order by tdetl.name_detl
----

со следующим планом выполнения:

----
Select Expression
    -> Sort (record length: 32860, key length: 36)
        -> Nested Loop Join (inner)
            -> Table "TMAIN" Full Scan
            -> Filter
                -> Table "TDETL" Access By ID
                    -> Bitmap
                        -> Index "FK_TABLE1_1" Range Scan (full match)
----

В этом случае размер каждой сортируемой записи составляет 32860+36 байт. Это может привести к созданию очень больших файлов сортировки, которые будут записаны на диск, и выполнение запроса может замедлиться.

С параметром `SortDataStorageThreshold=16384` или `InlineSortThreshold=16384` Firebird будет использовать метод доступа REFETCH, гв котором сортируется только ключ, а данные перечитываются из базы данных:

----
Select Expression
    -> Refetch
        -> Sort (record length: 76, key length: 36)
            -> Nested Loop Join (inner)
----

Такой подход позволяет существенно (в 2-5 раз) ускорить запросы с сортировкой очень широких наборов записей (обычно это тяжелые отчеты).

.Обратите внимание!
[NOTE]
====
Не рекомендуется устанавливать `SortDataStorageThreshold` (`InlineSortThreshold`) меньше чем 2048 байт.
====

<<<

[[hqbird-performance-multi-threaded]]
== Многопоточные sweep, backup, restore

В HQbird появилась возможность многопоточного выполнения очистки, резервного копирования и восстановления, что ускоряет их работу от 2х до 6 раз (в зависимости от конкретной базы). Многопоточные операции работают в HQbird для Firebird 2.5, 3.0 и 4.0 на любых архитектурах — Classic, SuperClassic, SuperServer. Для Firebird 5.0 многопоточные операции доступны в "`ванильной`" версии из коробки.

Чтобы включить многопоточное выполнение, утилиты командной строки `gfix` и `gbak` имеют параметр `–par _n_`, где `n` -- количество потоков, которые будут задействованы в конкретной операции. На практике выбор числа n следует соотносить с количеством доступных ядер процессора.

Примеры:

* `gfix –sweep database –par 8 ...`
* `gbak –b database backup –par 8 ...`
* `gbak –c backup database –par 8 ...`

Кроме того, чтобы ограничивать количество рабочих потоков и устанавливать их число по умолчанию, в `firebird.conf` введены два новых параметра, которые влияют только на sweep и restore, но не на резервное копирование:

----
# ============================
# Settings for parallel work
# ============================
#  Limit number of parallel workers for the single task. Per-process.
#  Valid values are from 1 (no parallelism) to 64. All other values
#  silently ignored and default value of 1 is used.
MaxParallelWorkers = 64
----

Пример: если вы установите `MaxParallelWorkers = 10`, вы сможете выполнять

* run `gfix –sweep database –par 10`
* run `gfix –sweep database –par 5` and `gbak –c –par 5 ...`

То есть всего будет использовано не более 10 потоков.
В случае превышения (например, если вы установили 6 потоков на sweep и 6 потоков на restore), для процесса, превышающего лимит, будет выведено сообщение "`No enough free worker attachments`").

Таким образом, чтобы включить многопоточные возможности`sweep и restore, вы должны установить параметр `MaxParallelWorkers` в `firebird.conf`.

----
MaxParallelWorkers = 64
----

и перезапустить Firebird.

`ParallelWorkers` по умолчанию устанавливает количество потоков, используемых для sweep и restore, если не указана опция `–par _n_`.

----
#  Default number of parallel workers for the single task. Per-process.
#  Valid values are from 1 (no parallelism) to MaxParallelWorkers (above).
#  Values less than 1 is silently ignored and default value of 1 is used.
#
ParallelWorkers = 1
----

Например, если `ParallelWorkers = 8`, то запуск

----
gfix –sweep
----

без опции `-par _n_` будет использоваться 8 потоков для параллельного выполнения sweep.

[IMPORTANT]
====
До Firebird 5.0 в HQbird при восстановлении заполнение таблиц из резервной копии всегда выполняется в одном потоке, а распараллеливается только создание индексов. Таким образом, ускорение восстановления зависит от количества индексов в базе данных и их размера. Также параметр `ParallelWorkers` автоматически влияет на создание индексов, выполняемых операциями `CREATE INDEX` и `ALTER INDEX... ACTIVE`.

Начиная с Firebird 5.0 заполнение таблиц при восстановлении тоже используется параллелизм.
====

Как упоминалось выше, эти параметры не влияют на резервное копирование. Многопоточность резервного копирования регулируется только параметром `–par _n_` в командной строке:

* `gbak –b –par 6 ...`
* `gbak –b –par 8 –se ...`


[IMPORTANT]
====
Если база данных находится в состоянии single shutdown, когда к базе данных разрешено только 1 соединение, то в версии 2.5 sweep, и резервное копирование с `-par _2_` или более будут вызывать ошибку через несколько секунд после запуска:

* sweep -- connection lost to database
* backup -- ERROR: database ... shutdown (по протоколу xnet строка с этим сообщением не будет отображаться в журнале резервного копирования)

Это связано с тем, что для этих операций требуется соответствующее количество подключений к базе данных, более 1.

В 3.0 только резервное копирование выдает ошибку "`ERROR: database ... shutdown`", sweep будет работать

Многопоточное восстановление Firebird 2.5, 3.0, 4.0 и 5.0 создает базу данных в режиме shutdown multi, поэтому такие ошибки не возникают. Однако существует риск подключения к базе данных в процессе восстановления других приложений от `SYSDBA` или владельца.
====

.Notes
[NOTE]
====
* Новые параметры в `firebird.conf` влияют только на очистку и восстановление. Чтобы упростить администрирование и устранить двусмысленность, рекомендуется всегда явно указывать параметр `-par n` для `gfix` и `gbak`, если вам нужно выполнять многопоточные операции sweep, восстановления и резервного копирования. Например, если вы установите `ParallelWorkers = 4` и не укажете `-par n`, то sweep и восстановление будут использовать 4 потока по умолчанию, а резервное копирование будет использовать 1 поток, поскольку не использует значения из `firebird.conf` ни локально, ни с помощью `-se`.
* Прирост производительности не обязательно зависит от количества ядер процессора и их соответствия заданному значению `–par n`. Это зависит от количества ядер, архитектуры Firebird и производительности дисковой подсистемы (IOPS). Поэтому оптимальное значение `–par n` для вашей системы необходимо подобрать экспериментально.
====

<<<

[[hqbird-blob-append]]
== BLOB_APPEND function

Обычный оператор `||` (конкатенация) с аргументами BLOB создает временный BLOB для каждой пары аргументов с BLOB. Это может привести к чрезмерному потреблению памяти и увеличению размера файла базы данных. Функция `BLOB_APPEND` предназначена для объединения BLOB-объектов без создания промежуточных BLOB-объектов.

Результирующий BLOB-объект функции `BLOB_APPEND` остается открытым для записи, а не закрывается сразу после заполнения данными. Т.е. в такой BLOB можно добавлять столько раз, сколько необходимо. Движок помечает такой объект новым внутренним флагом `BLB_close_on_read` и автоматически закрывает его при необходимости.

*Available in*: DSQL, PSQL.

.Syntax:
----
BLOB_APPEND(<blob> [, <value1>, ... <valueN]>
----

.Parameters of BLOB_APPEND function
[cols="1,2", options="header"]
|===
| Параметр
| Описание

| blob
| BLOB или NULL.

| value
| Значение любого типа.
|===


*Return type*: временный не закрытый BLOB (т.е. открытый для записи), помеченный флагом
`BLB_close_on_read`.

Входные аргументы:

* Первый аргумент BLOB или `NULL`. Возможны следующие варианты:
** `NULL`:  создаётся новый временный не закрытый BLOB с флагом `BLB_close_on_read`
** постоянный BLOB (из таблицы) или временный уже закрытый BLOB:
создаст новый пустой незакрытый BLOB с флагом `BLB_close_on_read` и к нему будет добавлено содержимое первого BLOB
** временный незакрытый BLOB с флагом `BLB_close_on_read`: будет использоваться далее
* остальные аргументы могут быть любого типа. Для них определено следующее поведение:
** `NULL` игнорируется
** не-BLOB будут преобразованы в строку и добавлены к содержимому результата
** BLOB, при необходимости транслитерируются в набор символов первого аргумента, а их содержимое добавляется к результату.

Функция BLOB_APPEND возвращает временный незакрытый BLOB с флагом BLB_close_on_read. Это либо новый BLOB, либо тот же самый, что и в первом аргументе. Таким образом, серия операций типа `blob = BLOB_APPEND (blob, ...)` приведет к созданию не более одного BLOB (если вы не попытаетесь добавить BLOB к самому себе).
Этот BLOB-объект будет автоматически закрыт механизмом, когда клиент попытается прочитать его, назначить таблице или использовать в других выражениях, требующих чтения содержимого.

[NOTE]
====
Проверка BLOB-объекта на наличие значения `NULL` с использованием оператора `IS [NOT] NULL` не приводит к его чтению, поэтому временный BLOB-объект с флагом `BLB_close_on_read` не будет закрыт во время такой проверки.
====

[source,sql]
----
execute block
returns (b blob sub_type text)
as
begin
  -- создаёт временный незакрытый BLOB
  -- и запишет в него строку из второго аргумента
  b = blob_append(null, 'Hello ');
  -- добавляет две строки во временный BLOB без его закрытия
  b = blob_append(b, 'World', '!');
  -- сравнение BLOB со строкой закроет его, потому что для этого вам нужно прочитать BLOB
  if (b = 'Hello World!') then
  begin
  -- ...
  end
  -- создаст временный закрытый BLOB, добавив к нему строку
  b = b || 'Close';
  suspend;
end
----


[TIP]
====
Используйте функции `LIST` и `BLOB_APPEND` для объединения BLOB. Это позволит сэкономить потребление памяти, дисковый ввод-вывод и предотвратить рост базы данных из-за создания множества временных BLOB-объектов при использовании операторов конкатенации.
====


[example]
====
Допустим, вам нужно собрать JSON на стороне сервера. У нас есть PSQL пакет `JSON_UTILS` с набором функций для преобразования примитивных типов данных в нотацию JSON. Тогда построение JSON с использованием функции `BLOB_APPEND` будет выглядеть так:

[source,sql]
----
EXECUTE BLOCK
RETURNS (
    JSON_STR BLOB SUB_TYPE TEXT CHARACTER SET UTF8)
AS
  DECLARE JSON_M BLOB SUB_TYPE TEXT CHARACTER SET UTF8;
BEGIN
  FOR
      SELECT
          HORSE.CODE_HORSE,
          HORSE.NAME,
          HORSE.BIRTHDAY
      FROM HORSE
      WHERE HORSE.CODE_DEPARTURE = 15
      FETCH FIRST 1000 ROW ONLY
      AS CURSOR C
  DO
  BEGIN
    SELECT
      LIST(
          '{' ||
          JSON_UTILS.NUMERIC_PAIR('age', MEASURE.AGE) ||
          ',' ||
          JSON_UTILS.NUMERIC_PAIR('height', MEASURE.HEIGHT_HORSE) ||
          ',' ||
          JSON_UTILS.NUMERIC_PAIR('length', MEASURE.LENGTH_HORSE) ||
          ',' ||
          JSON_UTILS.NUMERIC_PAIR('chestaround', MEASURE.CHESTAROUND) ||
          ',' ||
          JSON_UTILS.NUMERIC_PAIR('wristaround', MEASURE.WRISTAROUND) ||
          ',' ||
          JSON_UTILS.NUMERIC_PAIR('weight', MEASURE.WEIGHT_HORSE) ||
          '}'
      ) AS JSON_M
    FROM MEASURE
    WHERE MEASURE.CODE_HORSE = :C.CODE_HORSE
    INTO JSON_M;

    JSON_STR = BLOB_APPEND(
      JSON_STR,
      IIF(JSON_STR IS NULL, '[', ',' || ascii_char(13)),
      '{',
      JSON_UTILS.INTEGER_PAIR('code_horse', C.CODE_HORSE),
      ',',
      JSON_UTILS.STRING_PAIR('name', C.NAME),
      ',',
      JSON_UTILS.TIMESTAMP_PAIR('birthday', C.BIRTHDAY),
      ',',
      JSON_UTILS.STRING_VALUE('measures') || ':[', JSON_M, ']',
      '}'
    );
  END
  JSON_STR = BLOB_APPEND(JSON_STR, ']');
  SUSPEND;
END
----

Аналогичный пример с использованием обычного оператора конкатенации `||` на порядок медленнее и выполняет в 1000 раз больше операций записи на диск.
====

<<<

[[hqbird-performance-left-to-inner]]
== Преобразование LEFT joins в INNER

HQbird позволяет преобразовывать `LEFT JOIN` в `INNER JOIN`, если условие `WHERE` нарушает правила внешнего соединения.

[NOTE]
====
Начиная с Firebird 5.0 это функциональность доступна в "`ванильной`" версии Firebird.
====

Пример:

[source,sql]
----
SELECT *
FROM T1 LEFT JOIN T2 ON T1.ID = T2.ID
WHERE T2.FIELD1 = 0
----

В этом случае условие `T2.FIELD1 = 0` эффективно удаляет все "`поддельные NULL`" строки `T2`, поэтому результат тот же, что и для `INNER JOIN`. Однако оптимизатор вынужден использовать порядок соединения T1->T2, хотя мог бы также рассмотреть T2->T1. Имеет смысл обнаружить этот случай во время обработки соединения и заменить `LEFT` на `INNER` перед началом оптимизации.

В первую очередь это предназначено для улучшения автоматически генерируемых (например, ORM) запросов.

[NOTE]
====
Эта оптимизация не будет включена, если фильтруется значение `NULL`, например

[source,sql]
----
SELECT *
FROM T1 LEFT JOIN T2 ON T1.ID = T2.ID
WHERE T2.ID IS NULL
----

или

----
SELECT *
FROM T1 LEFT JOIN T2 ON T1.ID = T2.ID
WHERE T2.ID IS NOT NULL
----
====
