[[_hqbird_performance]]
= Улучшения производительности

== Пул внешних подключений

HQbird поддерживает пул внешних подключений для Firebird 2.5 и Firebird 3. Стандартная сборка Firebird 4.0 и выше поддерживает создание внешних пулов соединений "`из коробки`". 

Пул внешних подключений позволяет выполнять инструкции `EXECUTE ON EXTERNAL` с меньшими затратами на повторное соединение с внешней базой данных.

[NOTE]
====
Обратите внимание: этот пул выделяется для каждого экземпляра Firebird.
====

Эта функция настраивается в файле `firebird.conf`:

[source]
----
# ============================
# Settings of External Connections Pool
# ============================

# Set the maximum number of inactive (idle) external connections to retain at
# the pool. Valid values are between 0 and 1000.
# If set to zero, pool is disabled,
# i.e. external connection is destroyed immediately after the use.
#
# Type: integer
#
#ExtConnPoolSize = 0

# Set the time before destroying inactive external connection, seconds.
# Valid values are between 1 and 86400.
#
# Type: integer
#
#ExtConnPoolLifeTime = 7200
----

С точки зрения приложения не требуется никаких дополнительных действий для использования или неиспользования -- пул включается или отключается в конфигурации сервера и абсолютно незаметно для приложений.

Для управления пулом существуют следующие команды:

* изменение размера пула
+
[source]
----
ALTER EXTERNAL CONNECTIONS POOL SET SIZE N
----
+
Пример: эта команда устанавливает размер пула на 190 подключений.
+
[source,sql]
----
ALTER EXTERNAL CONNECTIONS POOL SET SIZE 190
----
* изменение времени жизни неактивного соединение в пуле
+
[source]
----
ALTER EXTERNAL CONNECTIONS POOL
SET LIFETIME N {SECOND | MINUTE | HOUR}
----
+
Пример: эта команда ограничивает время жизни соединения в пуле до 1 часа.
+
[source,sql]
----
ALTER EXTERNAL CONNECTIONS POOL SET LIFETIME 1 HOUR
----
* очистить все соединения в пуле
+
[source,sql]
----
ALTER EXTERNAL CONNECTIONS POOL CLEAR ALL
----
* очистить самое старое соединение в пуле
+
[source,sql]
----
ALTER EXTERNAL CONNECTIONS POOL CLEAR OLDEST
----

Для получения информации о состоянии пула были введены новые контекстные переменные. Следующий пример демонстрирует их использование

[source,sql]
----
SELECT
  CAST(RDB$GET_CONTEXT('SYSTEM', 'EXT_CONN_POOL_SIZE') AS INT) AS POOL_SIZE,
  CAST(RDB$GET_CONTEXT('SYSTEM', 'EXT_CONN_POOL_IDLE_COUNT') AS INT) AS POOL_IDLE,
  CAST(RDB$GET_CONTEXT('SYSTEM', 'EXT_CONN_POOL_ACTIVE_COUNT') AS INT) AS POOL_ACTIVE,
  CAST(RDB$GET_CONTEXT('SYSTEM', 'EXT_CONN_POOL_LIFETIME') AS INT) AS POOL_LIFETIME
FROM RDB$DATABASE;
----

<<<

== Кеш подготовленных запросов

В HQbird есть возможность улучшить производительность движка Firebird (версии 4.0 и 5.0) в случае большого количества частых и быстрых SQL-запросов: кэширование подготовленных операторов SQL на стороне сервера. Начиная с Firebird 5.0 эта функция доступна в стандартной сборке "`из коробки`". 

=== Кеш подготовленных запросов в Firebird 3.0 и 4.0

Эту функцию можно включить в `firebird.conf` с помощью параметра `DSQLCacheSize`:

[source]
----
# Size of DSQL statements cache.
# Maximum number of statements to cache.
# Use with care as it is per-attachment and could lead to big memory usage.
# Value of zero disables caching.
# Per-database configurable.
# Type: integer
#DSQLCacheSize = 0
----

Это число указывает, сколько последних запросов для каждого подключения к базе данных необходимо кэшировать.

Чтобы применить новое значение, потребуется перезапуск Firebird.

По умолчанию `DSQLCacheSize` равен 0, что означает выключен. Мы рекомендуем осторожно включать его: начните со значений, таких как 4, 8, 16, чтобы найти лучший эффект производительности.

[NOTE]
====
Обратите внимание: включение кэширования подготовленных операторов увеличивает использование памяти.
====

=== Кеш подготовленных запросов в Firebird 5.0

В Firebird 5.0 кеш подготовленных запросов был переработан и включён в "`ванильную`" сборку. 

Кеш подготовленных запросов управляется параметром `MaxStatementCacheSize` в `firebird.conf`.

----
# ----------------------------
# Maximum statement cache size
#
# The maximum amount of RAM used to cache unused DSQL compiled statements.
# If set to 0 (zero), statement cache is disabled.
#
# Per-database configurable.
#
# Type: integer
#
#MaxStatementCacheSize = 2M
----

По умолчанию кеш подготовленных запросов включен. Для его отключения необходимо установить параметр `MaxStatementCacheSize` в 0.

<<<

== TempSpaceLogThreshold: мониторинг запросов с большими сортировками и BLOB

HQbird имеет новый параметр в `firebird.conf` in Firebird 2.5, Firebird 3.0, Firebird 4.0 и Firebird 5.0:

[source]
----
TempSpaceLogThreshold=1000000000 #bytes
----

Когда Firebird видит этот параметр, он записывает тексты запросов в `firebird.log` для запросов, которые производят большие сортировки (запросы с `GROUP BY`, `ORDER BY` и т. д.).


Когда такой запрос создаст файл сортировки, размер которого превышает указанный порог, в `firebird.log` появится следующее сообщение:

----
SRV-DB1	Wed Nov 28 21:55:36 2018
	Temporary space of type "sort" has exceeded threshold of 1000000000 bytes.
	Total size: 10716980736, cached: 1455423488 bytes, on disk: 9263120384 bytes.
	Query: select count(*) from (select lpad('',1000,uuid_to_char(gen_uuid())) s
	       from rdb$types a,rdb$types b, rdb$types c  order by 1)
----

*Total size*:: общий размер файла сортировки

*Cached*:: часть сортировки, уместившаяся во временное пространство (задается параметром `TempCacheLimit`)

*On disk*:: часть сортировки, которая была сохранена во временный файл, который может быть кэширован в памяти ОС или сохранен на диске (в папке, указанной параметром `TempDirectories`, или в временной папке по умолчанию)

Для очень больших BLOB в файле `firebird.log` появится следующее сообщение

----
SRV-DB1	Tue Nov 27 17:35:39 2018
	Temporary space of type "blob" has exceeded threshold of 500000000 bytes.
	Total size: 500377437, cached: 0 bytes, on disk: 501219328 bytes.
----

Используйте `TempSpaceLogThreshold` для поиска неоптимизированных запросов с большой сортировкой и большими BLOB-объектами. Начиная с Firebird 3.0 в нём также будет сообщаться о больших хеш-таблицах (возникают при HASH JOIN).

Если вы столкнулись с такими запросами, оптимизируйте их либо путем изменения самого SQL-запроса, либо попробуйте включить параметр `SortDataStorageThreshold`.

<<<

== SortDataStorageThreshold: REFETCH вместо SORT для широких наборов данных

HQbird поддерживает новый метод оптимизации REFETCH. Стандартная сборка Firebird версии 4.0 и выше поддерживает этот алгоритм оптимизации "`из коробки`".

В HQbird появился новый параметр `SortDataStorageThreshold` в `firebird.conf` (Firebird 3.0+):

[source]
----
SortDataStorageThreshold=16384 # bytes
----

[NOTE]
====
Начиная с версии 4.0 этот параметр был переименован в `InlineSortThreshold`.

[source]
----
InlineSortThreshold=16384 # bytes
----
====

Если размер записи, возвращаемой SQL-запросом, будет больше указанного порога, Firebird будет использовать другой подход для сортировки наборов записей: REFETCH вместо SORT.

Например, у нас есть следующий запрос

[source]
----
select tdetl.name_detl
    ,tmain.name_main
    ,tdetl.long_description
from tdetl
join tmain on tdetl.pid=tmain.id
order by tdetl.name_detl
----

со следующим планом выполнения:

----
Select Expression
    -> Sort (record length: 32860, key length: 36)
        -> Nested Loop Join (inner)
            -> Table "TMAIN" Full Scan
            -> Filter
                -> Table "TDETL" Access By ID
                    -> Bitmap
                        -> Index "FK_TABLE1_1" Range Scan (full match)
----

В этом случае размер каждой сортируемой записи составляет 32860+36 байт. Это может привести к созданию очень больших файлов сортировки, которые будут записаны на диск, и выполнение запроса может замедлиться.

С параметром `SortDataStorageThreshold=16384` или `InlineSortThreshold=16384` Firebird будет использовать метод доступа REFETCH, гв котором сортируется только ключ, а данные перечитываются из базы данных:

----
Select Expression
    -> Refetch
        -> Sort (record length: 76, key length: 36)
            -> Nested Loop Join (inner)
----

Такой подход позволяет существенно (в 2-5 раз) ускорить запросы с сортировкой очень широких наборов записей (обычно это тяжелые отчеты).

.Обратите внимание!
[NOTE]
====
Не рекомендуется устанавливать `SortDataStorageThreshold` (`InlineSortThreshold`) меньше чем 2048 байт.
====

<<<

[[_hqbird_performance_multi_threaded]]
== Multi-thread sweep, backup, restore

In HQbird, the possibility of multi-threaded execution of sweep, backup and restore has appeared, which speeds up
their work from 2x to 6 times (depending on the specific database). Multi-threaded operations work in HQbird
Firebird 2.5 and 3.0 (starting from builds 2.5.9.27143 and 3.0.5.3.31717 respectively),
in any architectures -- Classic, SuperClassic, SuperServer.

To enable multi-threaded execution, the `gfix` and `gbak` command-line utilities
have the `–par _n_` option, where `n` is the number of threads that will be involved in a particular operation.
In practice, choosing the number n should be correlated with the number of available processor cores.

For example

* `gfix –sweep database –par 8 ...`
* `gbak –b database backup –par 8 ...`
* `gbak –c backup database –par 8 ...`

Also, to control the number of threads and set their default number in `firebird.conf`, two new parameters
are introduced that affect only sweep and restore, but not backup:

----
# ============================
# Settings for parallel work
# ============================
#  Limit number of parallel workers for the single task. Per-process.
#  Valid values are from 1 (no parallelism) to 64. All other values
#  silently ignored and default value of 1 is used.
MaxParallelWorkers = 64
----

Example: if you set `MaxParallelWorkers = 10`, then you can

* run `gfix –sweep database –par 10`
* run `gfix –sweep database –par 5` and `gbak –c –par 5 ...`

That is, no more than 10 threads will be used in total.
In case of exceeding (for example, if you set 6 threads for sweep and 6 threads for restore), for a process that exceeds the limit, the message "`No enough free worker attachments`" will be displayed).

Thus, to enable the multi-threaded capabilities of sweep and restore, you must set the `MaxParallelWorkers` parameter in `firebird.conf`

----
MaxParallelWorkers = 64
----

and then restart Firebird.

The `ParallelWorkers` sets the number of threads used by sweep and restore by default if the `–par _n_` option is not specified.

----
#  Default number of parallel workers for the single task. Per-process.
#  Valid values are from 1 (no parallelism) to MaxParallelWorkers (above).
#  Values less than 1 is silently ignored and default value of 1 is used.
#
ParallelWorkers = 1
----

For example, if `ParallelWorkers = 8`, then starting

----
gfix –sweep
----

without the `–par _n_` option will use 8 threads to execute sweep in parallel.

[IMPORTANT]
====
For restore, filling tables from backup is always performed in one thread, and only creating indexes is parallelized.
Thus, the acceleration for restore depends on the number of indexes in the database and their size.
Also, the `ParallelWorkers` parameter automatically affects the creation of indexes performed by the `CREATE INDEX` and `ALTER INDEX ... ACTIVE` operations.
====

As mentioned above, these options do not affect backup.
The multi-threading of backup is regulated only by the `–par _n_` parameter in the command line:

* `gbak –b –par 6 ...`
* `gbak –b –par 8 –se ...`


[IMPORTANT]
====
If the database is in shutdown single state, when only 1 connection is allowed to the database, then in version 2.5 both sweep and backup with `–par _2_` or more will produce an error several seconds after starting:

* sweep -- connection lost to database
* backup -- ERROR: database ... shutdown (via xnet protocol, a line with this message will not be displayed in the backup log)

This is due to the fact that for these operations an appropriate number of database connections is required, more than 1.

In 3.0, only backup will throw an error "`ERROR: database ... shutdown`", sweep will work.

Multi-threaded restore, Firebird 2.5, 3.0 and 4.0, creates the database in shutdown multi mode, so such errors do not occur.
However, there is a risk of connecting other applications from SYSDBA or the owner to the database in the restore process.
====

.Notes
[NOTE]
====
* The new parameters in `firebird.conf` only affect sweep and restore, to simplify administration and eliminate
ambiguity, it is recommended that you always explicitly specify the `–par n` parameter
for `gfix` and `gbak` if you need to perform multi-threaded sweep, restore, and backup operations.
For example, if you set `ParallelWorkers = 4` and do not specify `–par n`, then sweep and restore will use 4
threads by default, and backup will use 1 thread, because it does not use the values from `firebird.conf` neither
locally nor with `–se`.
* The performance improvement does not necessarily depend on the number of processor cores and their compliance
with the set value `–par n`. It depends on the number of cores, the Firebird architecture, and the disk subsystem
performance (IOPS). Therefore, the optimal value `–par n` for your system must be selected experimentally.
====

<<<

[[_hqbird_blob_append]]
== BLOB_APPEND function

Regular operator `||` (concatenation) with BLOB arguments creates temporary BLOB per every pair of args
with BLOB. This could lead to the excessive memory consumption and growth of database file. The `BLOB_APPEND` function is designed to concatenate BLOBs without creating intermediate BLOBs.

In order to achieve this, the result BLOB is left open for writing instead of been closed immediately after it is filled with data. I.e. such blob could be appended as many times as required. Engine marks such blob with new internal flag `BLB_close_on_read` and closes it automatically when necessary.

*Available in*: DSQL, PSQL.

.Syntax:
----
BLOB_APPEND(<blob> [, <value1>, ... <valueN]>
----

.Parameters of BLOB_APPEND function
[cols="1,2", options="header"]
|===
| Parameter
| Description

| blob
| BLOB or NULL.

| value
| Any type of value.
|===


*Return type*: BLOB, temporary, not closed (i.e. open for writting), marked by flag
`BLB_close_on_read`.

Input Arguments:

* The first argument is BLOB or NULL. The following options are possible:
** NULL:  creates new temporary blob, not closed, with flag `BLB_close_on_read`
** permanent BLOB (from table) or temporary already closed BLOB:
will create a new empty unclosed BLOB with the flag `BLB_close_on_read` and the contents of the first BLOB will be added to it
** temporary unclosed BLOB with the `BLB_close_on_read` flag: it will be used further
* other arguments can be of any type. The following behavior is defined for them:
** NULL ignored
** non-BLOBs are converted to string (as usual) and appended to the content of the result
** BLOBs, if necessary, are transliterated to the character set of the first argument and their contents are appended to the result

The `BLOB_APPEND` function returns a temporary unclosed BLOB with the` BLB_close_on_read` flag.
This is either a new BLOB or the same as in the first argument. Thus, a series of operations like `blob = BLOB_APPEND (blob, ...)` will result in the creation of at most one BLOB
(unless you try to add a BLOB to itself).
This BLOB will be automatically closed by the engine when the client tries to read it, assign it to a table, or use it in other expressions that require reading the content.

[NOTE]
====
Testing a BLOB for NULL value using the `IS [NOT] NULL` operator does not read it, and therefore a temporary BLOB with the` BLB_close_on_read` flag will not be closed during such test.
====

[source,sql]
----
execute block
returns (b blob sub_type text)
as
begin
  -- will create a new temporary not closed BLOB
  -- and will write to it the string from the 2nd argument
  b = blob_append(null, 'Hello ');
  -- adds two strings to the temporary BLOB without closing it
  b = blob_append(b, 'World', '!');
  -- comparing a BLOB with a string will close it, because for this you need to read the BLOB
  if (b = 'Hello World!') then
  begin
  -- ...
  end
  -- will create a temporary closed BLOB by adding a string to it
  b = b || 'Close';
  suspend;
end
----


[TIP]
====
Use the `LIST` and` BLOB_APPEND` functions to concatenate BLOBs. This will save memory consumption, disk I/O,
and prevent database growth due to the creation of many temporary BLOBs when using concatenation operators.
====


[example]
====
Let's say you need to build JSON on the server side. We have a PSQL package `JSON_UTILS` with a set of functions for converting primitive data types to JSON notation.
Then the JSON building using the `BLOB_APPEND` function will look like this:

[source,sql]
----
EXECUTE BLOCK
RETURNS (
    JSON_STR BLOB SUB_TYPE TEXT CHARACTER SET UTF8)
AS
  DECLARE JSON_M BLOB SUB_TYPE TEXT CHARACTER SET UTF8;
BEGIN
  FOR
      SELECT
          HORSE.CODE_HORSE,
          HORSE.NAME,
          HORSE.BIRTHDAY
      FROM HORSE
      WHERE HORSE.CODE_DEPARTURE = 15
      FETCH FIRST 1000 ROW ONLY
      AS CURSOR C
  DO
  BEGIN
    SELECT
      LIST(
          '{' ||
          JSON_UTILS.NUMERIC_PAIR('age', MEASURE.AGE) ||
          ',' ||
          JSON_UTILS.NUMERIC_PAIR('height', MEASURE.HEIGHT_HORSE) ||
          ',' ||
          JSON_UTILS.NUMERIC_PAIR('length', MEASURE.LENGTH_HORSE) ||
          ',' ||
          JSON_UTILS.NUMERIC_PAIR('chestaround', MEASURE.CHESTAROUND) ||
          ',' ||
          JSON_UTILS.NUMERIC_PAIR('wristaround', MEASURE.WRISTAROUND) ||
          ',' ||
          JSON_UTILS.NUMERIC_PAIR('weight', MEASURE.WEIGHT_HORSE) ||
          '}'
      ) AS JSON_M
    FROM MEASURE
    WHERE MEASURE.CODE_HORSE = :C.CODE_HORSE
    INTO JSON_M;

    JSON_STR = BLOB_APPEND(
      JSON_STR,
      IIF(JSON_STR IS NULL, '[', ',' || ascii_char(13)),
      '{',
      JSON_UTILS.INTEGER_PAIR('code_horse', C.CODE_HORSE),
      ',',
      JSON_UTILS.STRING_PAIR('name', C.NAME),
      ',',
      JSON_UTILS.TIMESTAMP_PAIR('birthday', C.BIRTHDAY),
      ',',
      JSON_UTILS.STRING_VALUE('measures') || ':[', JSON_M, ']',
      '}'
    );
  END
  JSON_STR = BLOB_APPEND(JSON_STR, ']');
  SUSPEND;
END
----

A similar example using the usual concatenation operator `||` is an order of magnitude slower and does 1000 times more disk writes.
====

<<<

[[_hqbird_performance_left_to_inner]]
== Transform LEFT joins into INNER

HQbird allow transform `LEFT` joins into `INNER` ones if the `WHERE` condition violates the outer join rules.

Example:

[source,sql]
----
SELECT *
FROM T1 LEFT JOIN T2 ON T1.ID = T2.ID
WHERE T2.FIELD1 = 0
----

In this case the condition `T2.FIELD1 = 0` effectively removes all the "fake NULL" rows of T2, so the result is the same
as for the `INNER JOIN`. However, the optimizer is forced to use the T1->T2 join order while T2->T1 could also be
considered. It makes sense to detect this case during join processing and internally replace `LEFT` with `INNER` before optimization starts.

This is primarily intended to improve "ad hoc" and machine-generated (e.g. ORM) queries.

[NOTE]
====
This optimization will not be enabled if a NULL value is checked, for example

[source,sql]
----
SELECT *
FROM T1 LEFT JOIN T2 ON T1.ID = T2.ID
WHERE T2.ID IS NULL
----

or

----
SELECT *
FROM T1 LEFT JOIN T2 ON T1.ID = T2.ID
WHERE T2.ID IS NOT NULL
----
====
